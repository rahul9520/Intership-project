{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b98548a",
   "metadata": {},
   "source": [
    "# Web Scraping Assignment 4\n",
    "Q.1 Scrape the details of most viewed videos on YouTube from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c90b2712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70562944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "driver.maximize_window()\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54350f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "#scraping Song Name\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='mw-content-text']/div[1]/table[3]/tbody/tr/td[1]\"):\n",
    "    name.append(i.text.split('\"')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "516e62d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Baby Shark Dance',\n",
       " 'Despacito',\n",
       " 'See You Again',\n",
       " 'Gangnam Style',\n",
       " 'Baby',\n",
       " 'Bad Romance',\n",
       " 'Charlie Bit My Finger',\n",
       " 'Evolution of Dance',\n",
       " 'Girlfriend',\n",
       " 'Evolution of Dance',\n",
       " 'Music Is My Hot Hot Sex',\n",
       " 'Evolution of Dance',\n",
       " 'Pokemon Theme Music Video',\n",
       " 'Myspace – The Movie',\n",
       " 'Phony Photo Booth',\n",
       " 'The Chronic of Narnia Rap',\n",
       " 'Ronaldinho: Touch of Gold',\n",
       " 'I/O Brush',\n",
       " 'Me at the zoo']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "645b6e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist=[]\n",
    "#scraping Artist name\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='mw-content-text']/div[1]/table[3]/tbody/tr/td[2]\"):\n",
    "    artist.append(i.text.split('[')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b13d75d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Pinkfong Baby Shark - Kids' Songs & Stories\",\n",
       " 'Luis Fonsi',\n",
       " 'Wiz Khalifa',\n",
       " 'Psy',\n",
       " 'Justin Bieber',\n",
       " 'Lady Gaga',\n",
       " 'HDCYT',\n",
       " 'Judson Laipply',\n",
       " 'RCA Records',\n",
       " 'Judson Laipply',\n",
       " 'CLARUSBARTEL72',\n",
       " 'Judson Laipply',\n",
       " 'Smosh',\n",
       " 'eggtea',\n",
       " 'mugenized',\n",
       " 'youtubedude',\n",
       " 'Nikesoccer',\n",
       " 'larfus',\n",
       " 'jawed']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f40560c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload=[]\n",
    "#scraping the Uploaded date\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='mw-content-text']/div[1]/table[3]/tbody/tr/td[4]\"):\n",
    "    upload.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2738ced4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['June 17, 2016',\n",
       " 'January 12, 2017',\n",
       " 'April 6, 2015',\n",
       " 'July 15, 2012',\n",
       " 'February 19, 2010',\n",
       " 'November 24, 2009',\n",
       " 'May 22, 2007',\n",
       " 'April 6, 2006',\n",
       " 'February 27, 2007',\n",
       " 'April 6, 2006',\n",
       " 'April 9, 2007',\n",
       " 'April 6, 2006',\n",
       " 'November 28, 2005',\n",
       " 'January 31, 2006',\n",
       " 'December 1, 2005',\n",
       " 'December 18, 2005',\n",
       " 'October 21, 2005',\n",
       " 'October 5, 2005',\n",
       " 'April 23, 2005']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8f47c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "views=[]\n",
    "#scraping the No of Views\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='mw-content-text']/div[1]/table[3]/tbody/tr/td[3]\"):\n",
    "    views.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f0e7000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7,046,700,000',\n",
       " '3,002,800,000',\n",
       " '2,894,000,000',\n",
       " '803,700,000',\n",
       " '245,400,000',\n",
       " '178,400,000',\n",
       " '128,900,000',\n",
       " '118,900,000',\n",
       " '92,600,000',\n",
       " '78,400,000',\n",
       " '76,600,000',\n",
       " '10,600,000',\n",
       " '4,300,000',\n",
       " '2,700,000',\n",
       " '3,400,000',\n",
       " '2,300,000',\n",
       " '255,000',\n",
       " '247,000',\n",
       " '1']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6369d49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Uploaded Date</th>\n",
       "      <th>No of Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>7,046,700,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>3,002,800,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>2,894,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>803,700,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baby</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>February 19, 2010</td>\n",
       "      <td>245,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bad Romance</td>\n",
       "      <td>Lady Gaga</td>\n",
       "      <td>November 24, 2009</td>\n",
       "      <td>178,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Charlie Bit My Finger</td>\n",
       "      <td>HDCYT</td>\n",
       "      <td>May 22, 2007</td>\n",
       "      <td>128,900,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Evolution of Dance</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>118,900,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Girlfriend</td>\n",
       "      <td>RCA Records</td>\n",
       "      <td>February 27, 2007</td>\n",
       "      <td>92,600,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Evolution of Dance</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>78,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Music Is My Hot Hot Sex</td>\n",
       "      <td>CLARUSBARTEL72</td>\n",
       "      <td>April 9, 2007</td>\n",
       "      <td>76,600,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Evolution of Dance</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>10,600,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pokemon Theme Music Video</td>\n",
       "      <td>Smosh</td>\n",
       "      <td>November 28, 2005</td>\n",
       "      <td>4,300,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Myspace – The Movie</td>\n",
       "      <td>eggtea</td>\n",
       "      <td>January 31, 2006</td>\n",
       "      <td>2,700,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Phony Photo Booth</td>\n",
       "      <td>mugenized</td>\n",
       "      <td>December 1, 2005</td>\n",
       "      <td>3,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Chronic of Narnia Rap</td>\n",
       "      <td>youtubedude</td>\n",
       "      <td>December 18, 2005</td>\n",
       "      <td>2,300,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ronaldinho: Touch of Gold</td>\n",
       "      <td>Nikesoccer</td>\n",
       "      <td>October 21, 2005</td>\n",
       "      <td>255,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I/O Brush</td>\n",
       "      <td>larfus</td>\n",
       "      <td>October 5, 2005</td>\n",
       "      <td>247,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Me at the zoo</td>\n",
       "      <td>jawed</td>\n",
       "      <td>April 23, 2005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name                                       Artist  \\\n",
       "0            Baby Shark Dance  Pinkfong Baby Shark - Kids' Songs & Stories   \n",
       "1                   Despacito                                   Luis Fonsi   \n",
       "2               See You Again                                  Wiz Khalifa   \n",
       "3               Gangnam Style                                          Psy   \n",
       "4                        Baby                                Justin Bieber   \n",
       "5                 Bad Romance                                    Lady Gaga   \n",
       "6       Charlie Bit My Finger                                        HDCYT   \n",
       "7          Evolution of Dance                               Judson Laipply   \n",
       "8                  Girlfriend                                  RCA Records   \n",
       "9          Evolution of Dance                               Judson Laipply   \n",
       "10    Music Is My Hot Hot Sex                               CLARUSBARTEL72   \n",
       "11         Evolution of Dance                               Judson Laipply   \n",
       "12  Pokemon Theme Music Video                                        Smosh   \n",
       "13        Myspace – The Movie                                       eggtea   \n",
       "14          Phony Photo Booth                                    mugenized   \n",
       "15  The Chronic of Narnia Rap                                  youtubedude   \n",
       "16  Ronaldinho: Touch of Gold                                   Nikesoccer   \n",
       "17                  I/O Brush                                       larfus   \n",
       "18              Me at the zoo                                        jawed   \n",
       "\n",
       "        Uploaded Date    No of Views  \n",
       "0       June 17, 2016  7,046,700,000  \n",
       "1    January 12, 2017  3,002,800,000  \n",
       "2       April 6, 2015  2,894,000,000  \n",
       "3       July 15, 2012    803,700,000  \n",
       "4   February 19, 2010    245,400,000  \n",
       "5   November 24, 2009    178,400,000  \n",
       "6        May 22, 2007    128,900,000  \n",
       "7       April 6, 2006    118,900,000  \n",
       "8   February 27, 2007     92,600,000  \n",
       "9       April 6, 2006     78,400,000  \n",
       "10      April 9, 2007     76,600,000  \n",
       "11      April 6, 2006     10,600,000  \n",
       "12  November 28, 2005      4,300,000  \n",
       "13   January 31, 2006      2,700,000  \n",
       "14   December 1, 2005      3,400,000  \n",
       "15  December 18, 2005      2,300,000  \n",
       "16   October 21, 2005        255,000  \n",
       "17    October 5, 2005        247,000  \n",
       "18     April 23, 2005              1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video={'Name':name,'Artist':artist,'Uploaded Date':upload,'No of Views':views}\n",
    "df=pd.DataFrame(data=video)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9272eac1",
   "metadata": {},
   "source": [
    "# Q2 Scrape the details team India’s international fixtures from bcci.tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d7f90e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.bcci.tv\")\n",
    "driver.maximize_window()\n",
    "\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d97c4be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on International tab\n",
    "driver.find_element(By.XPATH,'//*[@id=\"navigation\"]/ul[1]/li[2]/a').click()\n",
    "\n",
    "time.sleep(1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72dde755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ICC MENS T20 WORLD CUP 2022',\n",
       " 'ICC MENS T20 WORLD CUP 2022',\n",
       " 'ICC MENS T20 WORLD CUP 2022',\n",
       " 'ICC MENS T20 WORLD CUP 2022',\n",
       " 'ICC MENS T20 WORLD CUP 2022']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Title=[]\n",
    "#scraping the Title Name\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]'):\n",
    "    Title.append(i.text)\n",
    "    \n",
    "Title   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b10f90d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['India vs Pakistan',\n",
       " 'India vs TBD',\n",
       " 'India vs South Africa',\n",
       " 'India vs Bangladesh',\n",
       " 'India vs TBD']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Series=[]\n",
    "#scraping the series name\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"fixture-card-mid d-flex align-items-center justify-content-between\"]'):\n",
    "    Series.append(i.text.replace('\\n',' '))\n",
    "    \n",
    "Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "370bbdaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Melbourne Cricket Ground,',\n",
       " 'Sydney Cricket Ground,',\n",
       " 'Perth Stadium,',\n",
       " 'Adelaide Oval,',\n",
       " 'Melbourne Cricket Ground,']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Place=[]\n",
    "#scraping the place\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]'):\n",
    "    Place.append(i.text)\n",
    "    \n",
    "Place   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97e5da48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23 OCT 2022', '27 OCT 2022', '30 OCT 2022', '2 NOV 2022', '6 NOV 2022']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Date=[]\n",
    "#scraping the date\n",
    "for i in driver.find_elements(By.XPATH,'//h5[@class=\"ng-binding\"]'):\n",
    "    Date.append(i.text)\n",
    "    \n",
    "Date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71950d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1:30 PM IST', '12:30 PM IST', '4:30 PM IST', '1:30 PM IST', '1:30 PM IST']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time=[]\n",
    "#scraping the time\n",
    "for i in driver.find_elements(By.XPATH,'//h5[@class=\"text-right ng-binding\"]'):\n",
    "    Time.append(i.text)\n",
    "    \n",
    "Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e869ac54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5 5 5 5\n"
     ]
    }
   ],
   "source": [
    "print(len(Title),len(Series),len(Place),len(Date),len(Time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60e33cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2022</td>\n",
       "      <td>India vs Pakistan</td>\n",
       "      <td>Melbourne Cricket Ground,</td>\n",
       "      <td>23 OCT 2022</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2022</td>\n",
       "      <td>India vs TBD</td>\n",
       "      <td>Sydney Cricket Ground,</td>\n",
       "      <td>27 OCT 2022</td>\n",
       "      <td>12:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2022</td>\n",
       "      <td>India vs South Africa</td>\n",
       "      <td>Perth Stadium,</td>\n",
       "      <td>30 OCT 2022</td>\n",
       "      <td>4:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2022</td>\n",
       "      <td>India vs Bangladesh</td>\n",
       "      <td>Adelaide Oval,</td>\n",
       "      <td>2 NOV 2022</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2022</td>\n",
       "      <td>India vs TBD</td>\n",
       "      <td>Melbourne Cricket Ground,</td>\n",
       "      <td>6 NOV 2022</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Title                 Series  \\\n",
       "0  ICC MENS T20 WORLD CUP 2022      India vs Pakistan   \n",
       "1  ICC MENS T20 WORLD CUP 2022           India vs TBD   \n",
       "2  ICC MENS T20 WORLD CUP 2022  India vs South Africa   \n",
       "3  ICC MENS T20 WORLD CUP 2022    India vs Bangladesh   \n",
       "4  ICC MENS T20 WORLD CUP 2022           India vs TBD   \n",
       "\n",
       "                       Place         Date          Time  \n",
       "0  Melbourne Cricket Ground,  23 OCT 2022   1:30 PM IST  \n",
       "1     Sydney Cricket Ground,  27 OCT 2022  12:30 PM IST  \n",
       "2             Perth Stadium,  30 OCT 2022   4:30 PM IST  \n",
       "3             Adelaide Oval,   2 NOV 2022   1:30 PM IST  \n",
       "4  Melbourne Cricket Ground,   6 NOV 2022   1:30 PM IST  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the DataFrame\n",
    "bcci={'Title':Title,'Series':Series,'Place':Place,'Date':Date,'Time':Time}\n",
    "df=pd.DataFrame(data=bcci)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c0ce41",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of selenium exception from guru99.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7aa71b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n",
    "driver.maximize_window()\n",
    "\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "411191b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Year=[]\n",
    "Genre=[]\n",
    "Runtime=[]\n",
    "Ratings=[]\n",
    "Votes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4cdf484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Game of Thrones']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name=[]\n",
    "#scraping for name\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='main']/div/div[3]/div[3]/div[1]/div[2]/h3/a\"):\n",
    "    Name.append(i.text.split(':')[0])\n",
    "\n",
    "Name  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526b9e7c",
   "metadata": {},
   "source": [
    "# Q4 Scrape the details of State-wise GDP of India from statisticstime.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6ba8748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"http://statisticstimes.com/\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4020a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting to the Indian page under economy tab\n",
    "page=driver.find_element(By.XPATH,\"//div[@class='dropdown-content']/a[3]\")\n",
    "driver.get(page.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a36e7ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on GDP of indian states\n",
    "driver.find_element(By.XPATH,\"//ul[@style='list-style-type:none;margin-left:20px;']/li[1]/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "caf4d026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rank=[]\n",
    "#scraping for rank\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[1]\"):\n",
    "    Rank.append(i.text)\n",
    "    \n",
    "Rank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "095964f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maharashtra',\n",
       " 'Tamil Nadu',\n",
       " 'Uttar Pradesh',\n",
       " 'Gujarat',\n",
       " 'Karnataka',\n",
       " 'West Bengal',\n",
       " 'Rajasthan',\n",
       " 'Andhra Pradesh',\n",
       " 'Telangana',\n",
       " 'Madhya Pradesh',\n",
       " 'Kerala',\n",
       " 'Delhi',\n",
       " 'Haryana',\n",
       " 'Bihar',\n",
       " 'Punjab',\n",
       " 'Odisha',\n",
       " 'Assam',\n",
       " 'Chhattisgarh',\n",
       " 'Jharkhand',\n",
       " 'Uttarakhand',\n",
       " 'Jammu & Kashmir',\n",
       " 'Himachal Pradesh',\n",
       " 'Goa',\n",
       " 'Tripura',\n",
       " 'Chandigarh',\n",
       " 'Puducherry',\n",
       " 'Meghalaya',\n",
       " 'Sikkim',\n",
       " 'Manipur',\n",
       " 'Nagaland',\n",
       " 'Arunachal Pradesh',\n",
       " 'Mizoram',\n",
       " 'Andaman & Nicobar Islands']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state=[]\n",
    "#scraping for state state\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[2]\"):\n",
    "    state.append(i.text)\n",
    "    \n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7d3df4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,632,792',\n",
       " '1,630,208',\n",
       " '1,584,764',\n",
       " '1,502,899',\n",
       " '1,493,127',\n",
       " '1,089,898',\n",
       " '942,586',\n",
       " '862,957',\n",
       " '861,031',\n",
       " '809,592',\n",
       " '781,653',\n",
       " '774,870',\n",
       " '734,163',\n",
       " '530,363',\n",
       " '526,376',\n",
       " '487,805',\n",
       " '315,881',\n",
       " '304,063',\n",
       " '297,204',\n",
       " '245,895',\n",
       " '155,956',\n",
       " '153,845',\n",
       " '73,170',\n",
       " '49,845',\n",
       " '42,114',\n",
       " '34,433',\n",
       " '33,481',\n",
       " '28,723',\n",
       " '27,870',\n",
       " '27,283',\n",
       " '24,603',\n",
       " '22,287',\n",
       " '-']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSDP2=[]\n",
    "#scraping for GSDP2\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[4]\"):\n",
    "    GSDP2.append(i.text)\n",
    "    \n",
    "GSDP2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96181cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13.94%',\n",
       " '8.63%',\n",
       " '8.39%',\n",
       " '7.96%',\n",
       " '7.91%',\n",
       " '5.77%',\n",
       " '4.99%',\n",
       " '4.57%',\n",
       " '4.56%',\n",
       " '4.29%',\n",
       " '4.14%',\n",
       " '4.10%',\n",
       " '3.89%',\n",
       " '2.81%',\n",
       " '2.79%',\n",
       " '2.58%',\n",
       " '1.67%',\n",
       " '1.61%',\n",
       " '1.57%',\n",
       " '1.30%',\n",
       " '0.83%',\n",
       " '0.81%',\n",
       " '0.39%',\n",
       " '0.26%',\n",
       " '0.22%',\n",
       " '0.18%',\n",
       " '0.18%',\n",
       " '0.15%',\n",
       " '0.15%',\n",
       " '0.14%',\n",
       " '0.13%',\n",
       " '0.12%',\n",
       " '-']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "share=[]\n",
    "#scraping for share\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[5]\"):\n",
    "    share.append(i.text)\n",
    "    \n",
    "share  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39be45aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['399.921',\n",
       " '247.629',\n",
       " '240.726',\n",
       " '228.290',\n",
       " '226.806',\n",
       " '165.556',\n",
       " '143.179',\n",
       " '131.083',\n",
       " '130.791',\n",
       " '122.977',\n",
       " '118.733',\n",
       " '117.703',\n",
       " '111.519',\n",
       " '80.562',\n",
       " '79.957',\n",
       " '74.098',\n",
       " '47.982',\n",
       " '46.187',\n",
       " '45.145',\n",
       " '37.351',\n",
       " '23.690',\n",
       " '23.369',\n",
       " '11.115',\n",
       " '7.571',\n",
       " '6.397',\n",
       " '5.230',\n",
       " '5.086',\n",
       " '4.363',\n",
       " '4.233',\n",
       " '4.144',\n",
       " '3.737',\n",
       " '3.385',\n",
       " '-']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDP=[]\n",
    "#scraping for GDP\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[6]\"):\n",
    "    GDP.append(i.text)\n",
    "    \n",
    "GDP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85911163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 33 33 33 33\n"
     ]
    }
   ],
   "source": [
    "print(len(Rank),len(state),len(GSDP2),len(share),len(GDP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "08d44b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP 18-19</th>\n",
       "      <th>Share 18-19</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP 18-19 Share 18-19      GDP\n",
       "0     1                Maharashtra  2,632,792      13.94%  399.921\n",
       "1     2                 Tamil Nadu  1,630,208       8.63%  247.629\n",
       "2     3              Uttar Pradesh  1,584,764       8.39%  240.726\n",
       "3     4                    Gujarat  1,502,899       7.96%  228.290\n",
       "4     5                  Karnataka  1,493,127       7.91%  226.806\n",
       "5     6                West Bengal  1,089,898       5.77%  165.556\n",
       "6     7                  Rajasthan    942,586       4.99%  143.179\n",
       "7     8             Andhra Pradesh    862,957       4.57%  131.083\n",
       "8     9                  Telangana    861,031       4.56%  130.791\n",
       "9    10             Madhya Pradesh    809,592       4.29%  122.977\n",
       "10   11                     Kerala    781,653       4.14%  118.733\n",
       "11   12                      Delhi    774,870       4.10%  117.703\n",
       "12   13                    Haryana    734,163       3.89%  111.519\n",
       "13   14                      Bihar    530,363       2.81%   80.562\n",
       "14   15                     Punjab    526,376       2.79%   79.957\n",
       "15   16                     Odisha    487,805       2.58%   74.098\n",
       "16   17                      Assam    315,881       1.67%   47.982\n",
       "17   18               Chhattisgarh    304,063       1.61%   46.187\n",
       "18   19                  Jharkhand    297,204       1.57%   45.145\n",
       "19   20                Uttarakhand    245,895       1.30%   37.351\n",
       "20   21            Jammu & Kashmir    155,956       0.83%   23.690\n",
       "21   22           Himachal Pradesh    153,845       0.81%   23.369\n",
       "22   23                        Goa     73,170       0.39%   11.115\n",
       "23   24                    Tripura     49,845       0.26%    7.571\n",
       "24   25                 Chandigarh     42,114       0.22%    6.397\n",
       "25   26                 Puducherry     34,433       0.18%    5.230\n",
       "26   27                  Meghalaya     33,481       0.18%    5.086\n",
       "27   28                     Sikkim     28,723       0.15%    4.363\n",
       "28   29                    Manipur     27,870       0.15%    4.233\n",
       "29   30                   Nagaland     27,283       0.14%    4.144\n",
       "30   31          Arunachal Pradesh     24,603       0.13%    3.737\n",
       "31   32                    Mizoram     22,287       0.12%    3.385\n",
       "32   33  Andaman & Nicobar Islands          -           -        -"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time.sleep(1)\n",
    "#creating the DataFrame\n",
    "gdp_State={'Rank':Rank,'State':state,'GSDP 18-19':GSDP2,'Share 18-19':share,'GDP':GDP}\n",
    "df=pd.DataFrame(data=gdp_State)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174a0879",
   "metadata": {},
   "source": [
    "# Q7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/ You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Designation\n",
    "\n",
    "C) Company\n",
    "\n",
    "D) Skills they hire for\n",
    "\n",
    "E) Location\n",
    "\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "03d6266a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Science recruiters from Naukri\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Skill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>UK - (london)</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "      <td>Analytics, Business Intelligence, Business Ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Techvantage Systems Pvt Ltd</td>\n",
       "      <td>Trivandrum</td>\n",
       "      <td>Machine Learning, algorithms, Go Getter, Compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Director</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>Indore</td>\n",
       "      <td>Technical Training, Software Development, Pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>CBL Data Science Private Limited</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Software Development, It Sales, Account Manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Priyanka Akiri</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Infinitive Software Solutions</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Oracle Dba, Data Science, Data Warehousing, ET...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Innominds Software</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Qa, Ui/ux, Java Developer, Java Architect, C++...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MoneyTap</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Business Intelligence, Data Warehousing, Data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>QuantMagnum Technologies Pvt. Ltd.</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Office Administration, Hr Administration, tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>SocialPrachar.com</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Social Media, digital media maketing, seo, smm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Vaishnavi Kudalkar</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Codeachive learning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Data Science, Python, Data Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>BISP Solutions</td>\n",
       "      <td>Bhopal</td>\n",
       "      <td>Big Data, Hadoop, Data Analytics, Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sakshi Chhikara</td>\n",
       "      <td>Assistant Manager HR</td>\n",
       "      <td>BIZ INFOTECNO PRIVATE LIMITED</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>React.js, Data Science, Java, Front End, Busin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ruchi Dhote</td>\n",
       "      <td>Senior Executive Talent Acquisition</td>\n",
       "      <td>Bristlecone India Ltd</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Qlikview, Qlik Sense, Microsoft Azure, Power B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Easi Tax</td>\n",
       "      <td>Navi Mumbai</td>\n",
       "      <td>Telecalling, Client Interaction, Marketing, Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Riya Rajesh</td>\n",
       "      <td>Manager Talent Acquisition</td>\n",
       "      <td>Novelworx Digital Solutions</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Rashmi Bhattacharjee</td>\n",
       "      <td>HR Head</td>\n",
       "      <td>AXESTRACK SOFTWARE SOLUTIONS PRIVATE...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Corporate Sales, Software Development, Softwar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Faizan Kareem</td>\n",
       "      <td>HR MANAGER</td>\n",
       "      <td>FirstTech Consaltants Pvt.Ltd</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Data Analytics, Data Science, Machine Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Rithika dadwal</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Affine Analytics</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Data Science, Machine Learning, Python, R, Dee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sandhya Khandagale</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Compumatrice Multimedia Pvt Ltd</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Big Data, Data Science, Artificial Intelligenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Shaun Rao</td>\n",
       "      <td>Manager Human Resources</td>\n",
       "      <td>Exela Technologies</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Java, Net, Angularjs, Hr, Infrastructure, Mana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Azahar Shaikh</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>NEAL ANALYTICS SERVICES PVT LTD</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Manas</td>\n",
       "      <td>Lead Talent acquisition</td>\n",
       "      <td>Autumn Leaf Consulting Services Private...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Software Architecture, Vp Engineering, Product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>kumar</td>\n",
       "      <td>Proprietor</td>\n",
       "      <td>trainin</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Data Science, Hadoop, Rpas, Devops, Python, Aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sunil Vedula</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Nanoprecise Sci Corp</td>\n",
       "      <td>-</td>\n",
       "      <td>Signal Processing, Machine Learning, Neural Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Rajat Kumar</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>R.S Consultancy &amp;amp; Services</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Web Technologies, Project Management, Software...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Dhruv Dev Dubey</td>\n",
       "      <td>Company Recruitment Head</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Server Administartion, Verilog, Vhdl, Digital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Jayanth N</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Dollarbird Information Services Pvt, Ltd</td>\n",
       "      <td>Mysoru / Mysore</td>\n",
       "      <td>Data Analytics, Managed Services, Team Leading...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Avodha</td>\n",
       "      <td>Business Development Associate</td>\n",
       "      <td>Nikitha Palaparthi</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Ethical Hacking, Security Operations Center, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Priya Khare</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>Independent Consultant</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Data Science, Artificial Intelligence, analyti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>ASCO consulting</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Machine Learning, Artificial Intelligence, Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Kanan</td>\n",
       "      <td>senior technology instructor</td>\n",
       "      <td>NY INST</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>C, C++, Artificial Intelligence, Python, Php, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Shashikant Chaudhary</td>\n",
       "      <td>HR Recruiter/HR Excutive</td>\n",
       "      <td>3D India Staffing Research &amp;amp; Consulting...</td>\n",
       "      <td>Aligarh</td>\n",
       "      <td>Relationship Management, Retail Sales, Private...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Brad</td>\n",
       "      <td>Manager, Technical Recruiting</td>\n",
       "      <td>O.C. Tanner</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>Data Science, Software Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Rutuja Pawar</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>Demand Matrix</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Data Science, Big Data Analytics, Digital Mark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Madhusudhan Sridhar</td>\n",
       "      <td>Erp Implementer</td>\n",
       "      <td>MADHUSUDHAN SRIDHAR</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Data Science, Recruitment, Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ankit Sinha</td>\n",
       "      <td>Head Analytics</td>\n",
       "      <td>Suntech Global</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>B.Tech, Tableau, Statistics, R, Analytics, Tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Gaurav Chouhan</td>\n",
       "      <td>Chief Technical Officer</td>\n",
       "      <td>Strategic Consulting Lab</td>\n",
       "      <td>Indore</td>\n",
       "      <td>Software Development, Business Intelligence, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Rashi Kacker</td>\n",
       "      <td>Sr Product Manager</td>\n",
       "      <td>Impel Labs Pvt. Ltd.</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Data Science, Node.js, Angularjs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ashwini</td>\n",
       "      <td>Director Global Delivery</td>\n",
       "      <td>MRP Advisers</td>\n",
       "      <td>MYSORE</td>\n",
       "      <td>Data Science, Media Marketing, Resource Planni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Balaji Kolli</td>\n",
       "      <td>Co Founder</td>\n",
       "      <td>Saras Solutions India Pvt Ltd</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Data Analysis, Learning, Data Science, Compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>WildJasmine</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Java, Hadoop, R, Machine Learning, Spark, Flum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ROHIT Kumar</td>\n",
       "      <td>Architect</td>\n",
       "      <td>LNT Private Limited</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Software Development, Core Java, Unit Testing,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Amir Chowdhury</td>\n",
       "      <td>Managing Partner</td>\n",
       "      <td>Granular.ai</td>\n",
       "      <td>-</td>\n",
       "      <td>Machine Learning, Data Science, Product Manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>SREEDHAR</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Data Science, Machine Learning, Big Data Analy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name  \\\n",
       "0                                    Aakash Harit   \n",
       "1                            shravan Kumar Gaddam   \n",
       "2                        MARSIAN Technologies LLP   \n",
       "3                                    Anik Agrawal   \n",
       "4                                    subhas patel   \n",
       "5    Abhishek - Only Analytics Hiring - India and   \n",
       "6   Institute for Financial Management and Resear   \n",
       "7                                     Balu Ramesh   \n",
       "8                                   Asif Lucknowi   \n",
       "9                                 InstaFinancials   \n",
       "10                                 Priyanka Akiri   \n",
       "11                                Kalpana Dumpala   \n",
       "12                                        Mubarak   \n",
       "13                                 Kushal Rastogi   \n",
       "14                             Mahesh Babu Channa   \n",
       "15                             Vaishnavi Kudalkar   \n",
       "16                                   Kapil Devang   \n",
       "17                                Sakshi Chhikara   \n",
       "18                                    Ruchi Dhote   \n",
       "19                                  Manisha Yadav   \n",
       "20                                    Riya Rajesh   \n",
       "21                           Rashmi Bhattacharjee   \n",
       "22                                  Faizan Kareem   \n",
       "23                                 Rithika dadwal   \n",
       "24                             Sandhya Khandagale   \n",
       "25                                      Shaun Rao   \n",
       "26                                  Azahar Shaikh   \n",
       "27                                          Manas   \n",
       "28                                          kumar   \n",
       "29                                   Sunil Vedula   \n",
       "30                                    Rajat Kumar   \n",
       "31                                Dhruv Dev Dubey   \n",
       "32                                      Jayanth N   \n",
       "33                                         Avodha   \n",
       "34                                    Priya Khare   \n",
       "35                                    Amit Sharma   \n",
       "36                                          Kanan   \n",
       "37                           Shashikant Chaudhary   \n",
       "38                                           Brad   \n",
       "39                                   Rutuja Pawar   \n",
       "40                            Madhusudhan Sridhar   \n",
       "41                                    Ankit Sinha   \n",
       "42                                 Gaurav Chouhan   \n",
       "43                                   Rashi Kacker   \n",
       "44                                        Ashwini   \n",
       "45                                   Balaji Kolli   \n",
       "46                                 Rajani Nagaraj   \n",
       "47                                    ROHIT Kumar   \n",
       "48                                 Amir Chowdhury   \n",
       "49                                       SREEDHAR   \n",
       "\n",
       "                            Designation  \\\n",
       "0                            HR Manager   \n",
       "1                     Company Recruiter   \n",
       "2                            Company HR   \n",
       "3                     Company Recruiter   \n",
       "4                           Founder CEO   \n",
       "5           Recruitment Lead Consultant   \n",
       "6                     Programme Manager   \n",
       "7                      HR Administrator   \n",
       "8                              Director   \n",
       "9                        Human Resource   \n",
       "10                           HR Manager   \n",
       "11                     Executive Hiring   \n",
       "12                           Company HR   \n",
       "13                           Company HR   \n",
       "14                         HR Team Lead   \n",
       "15                         HR Executive   \n",
       "16                           HR Manager   \n",
       "17                 Assistant Manager HR   \n",
       "18  Senior Executive Talent Acquisition   \n",
       "19                         HR Executive   \n",
       "20           Manager Talent Acquisition   \n",
       "21                              HR Head   \n",
       "22                           HR MANAGER   \n",
       "23                         HR Recruiter   \n",
       "24                         HR Recruiter   \n",
       "25              Manager Human Resources   \n",
       "26                    Company Recruiter   \n",
       "27              Lead Talent acquisition   \n",
       "28                           Proprietor   \n",
       "29                                  CEO   \n",
       "30                          Founder CEO   \n",
       "31             Company Recruitment Head   \n",
       "32                      Project Manager   \n",
       "33       Business Development Associate   \n",
       "34                       Senior Manager   \n",
       "35                           Consultant   \n",
       "36         senior technology instructor   \n",
       "37             HR Recruiter/HR Excutive   \n",
       "38        Manager, Technical Recruiting   \n",
       "39                  Technical Recruiter   \n",
       "40                      Erp Implementer   \n",
       "41                       Head Analytics   \n",
       "42              Chief Technical Officer   \n",
       "43                   Sr Product Manager   \n",
       "44             Director Global Delivery   \n",
       "45                           Co Founder   \n",
       "46                           HR Manager   \n",
       "47                            Architect   \n",
       "48                     Managing Partner   \n",
       "49               Recruitment Consultant   \n",
       "\n",
       "                                           Company                  Location  \\\n",
       "0                             Data Science Network                     Delhi   \n",
       "1                    Shore Infotech India Pvt. Ltd  Hyderabad / Secunderabad   \n",
       "2                         MARSIAN Technologies LLP                      Pune   \n",
       "3            Enerlytics Software Solutions Pvt Ltd                 Ahmedabad   \n",
       "4                                  LibraryXProject             UK - (london)   \n",
       "5       Apidel Technologies Division of Transpower         Vadodara / Baroda   \n",
       "6                                             IFMR                   Chennai   \n",
       "7                      Techvantage Systems Pvt Ltd                Trivandrum   \n",
       "8                       Weupskill- Live Wire India                    Indore   \n",
       "9                 CBL Data Science Private Limited     Bengaluru / Bangalore   \n",
       "10                   Infinitive Software Solutions                 Hyderabad   \n",
       "11                              Innominds Software  Hyderabad / Secunderabad   \n",
       "12                                        MoneyTap     Bengaluru / Bangalore   \n",
       "13              QuantMagnum Technologies Pvt. Ltd.                    Mumbai   \n",
       "14                               SocialPrachar.com  Hyderabad / Secunderabad   \n",
       "15                             Codeachive learning                    Mumbai   \n",
       "16                                  BISP Solutions                    Bhopal   \n",
       "17                   BIZ INFOTECNO PRIVATE LIMITED                Chandigarh   \n",
       "18                           Bristlecone India Ltd                      Pune   \n",
       "19                                        Easi Tax               Navi Mumbai   \n",
       "20                     Novelworx Digital Solutions                    Cochin   \n",
       "21         AXESTRACK SOFTWARE SOLUTIONS PRIVATE...                     Delhi   \n",
       "22                   FirstTech Consaltants Pvt.Ltd  Hyderabad / Secunderabad   \n",
       "23                                Affine Analytics                      Pune   \n",
       "24                 Compumatrice Multimedia Pvt Ltd                      Pune   \n",
       "25                              Exela Technologies                      Pune   \n",
       "26                 NEAL ANALYTICS SERVICES PVT LTD                      Pune   \n",
       "27      Autumn Leaf Consulting Services Private...     Bengaluru / Bangalore   \n",
       "28                                         trainin     Bengaluru / Bangalore   \n",
       "29                            Nanoprecise Sci Corp                         -   \n",
       "30                  R.S Consultancy &amp; Services                     Delhi   \n",
       "31                                    Confidential     Bengaluru / Bangalore   \n",
       "32        Dollarbird Information Services Pvt, Ltd           Mysoru / Mysore   \n",
       "33                              Nikitha Palaparthi  Hyderabad / Secunderabad   \n",
       "34                          Independent Consultant     Bengaluru / Bangalore   \n",
       "35                                 ASCO consulting                 New Delhi   \n",
       "36                                         NY INST                   Chennai   \n",
       "37  3D India Staffing Research &amp; Consulting...                   Aligarh   \n",
       "38                                     O.C. Tanner            Salt Lake City   \n",
       "39                                   Demand Matrix                      Pune   \n",
       "40                             MADHUSUDHAN SRIDHAR     Bengaluru / Bangalore   \n",
       "41                                  Suntech Global                    Mumbai   \n",
       "42                        Strategic Consulting Lab                    Indore   \n",
       "43                            Impel Labs Pvt. Ltd.     Bengaluru / Bangalore   \n",
       "44                                    MRP Advisers                    MYSORE   \n",
       "45                   Saras Solutions India Pvt Ltd  Hyderabad / Secunderabad   \n",
       "46                                     WildJasmine     Bengaluru / Bangalore   \n",
       "47                             LNT Private Limited                    Mumbai   \n",
       "48                                     Granular.ai                         -   \n",
       "49     JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED  Hyderabad / Secunderabad   \n",
       "\n",
       "                                                Skill  \n",
       "0   Classic ASP Developer, Internet Marketing Prof...  \n",
       "1   .Net, Java, Data Science, Linux Administration...  \n",
       "2   Data Science, Artificial Intelligence, Machine...  \n",
       "3   Mean Stack, javascript, angularjs, mongodb, We...  \n",
       "4   Hadoop, Spark, Digital Strategy, Data Architec...  \n",
       "5   Analytics, Business Intelligence, Business Ana...  \n",
       "6                                        Data Science  \n",
       "7   Machine Learning, algorithms, Go Getter, Compu...  \n",
       "8   Technical Training, Software Development, Pres...  \n",
       "9   Software Development, It Sales, Account Manage...  \n",
       "10  Oracle Dba, Data Science, Data Warehousing, ET...  \n",
       "11  Qa, Ui/ux, Java Developer, Java Architect, C++...  \n",
       "12  Business Intelligence, Data Warehousing, Data ...  \n",
       "13  Office Administration, Hr Administration, tele...  \n",
       "14  Social Media, digital media maketing, seo, smm...  \n",
       "15               Data Science, Python, Data Analytics  \n",
       "16     Big Data, Hadoop, Data Analytics, Data Science  \n",
       "17  React.js, Data Science, Java, Front End, Busin...  \n",
       "18  Qlikview, Qlik Sense, Microsoft Azure, Power B...  \n",
       "19  Telecalling, Client Interaction, Marketing, Re...  \n",
       "20                                       Data Science  \n",
       "21  Corporate Sales, Software Development, Softwar...  \n",
       "22  Data Analytics, Data Science, Machine Learning...  \n",
       "23  Data Science, Machine Learning, Python, R, Dee...  \n",
       "24  Big Data, Data Science, Artificial Intelligenc...  \n",
       "25  Java, Net, Angularjs, Hr, Infrastructure, Mana...  \n",
       "26  Data Science, Artificial Intelligence, Machine...  \n",
       "27  Software Architecture, Vp Engineering, Product...  \n",
       "28  Data Science, Hadoop, Rpas, Devops, Python, Aw...  \n",
       "29  Signal Processing, Machine Learning, Neural Ne...  \n",
       "30  Web Technologies, Project Management, Software...  \n",
       "31  Server Administartion, Verilog, Vhdl, Digital ...  \n",
       "32  Data Analytics, Managed Services, Team Leading...  \n",
       "33  Ethical Hacking, Security Operations Center, S...  \n",
       "34  Data Science, Artificial Intelligence, analyti...  \n",
       "35  Machine Learning, Artificial Intelligence, Dat...  \n",
       "36  C, C++, Artificial Intelligence, Python, Php, ...  \n",
       "37  Relationship Management, Retail Sales, Private...  \n",
       "38                 Data Science, Software Engineering  \n",
       "39  Data Science, Big Data Analytics, Digital Mark...  \n",
       "40                  Data Science, Recruitment, Salary  \n",
       "41  B.Tech, Tableau, Statistics, R, Analytics, Tim...  \n",
       "42  Software Development, Business Intelligence, B...  \n",
       "43                   Data Science, Node.js, Angularjs  \n",
       "44  Data Science, Media Marketing, Resource Planni...  \n",
       "45  Data Analysis, Learning, Data Science, Compute...  \n",
       "46  Java, Hadoop, R, Machine Learning, Spark, Flum...  \n",
       "47  Software Development, Core Java, Unit Testing,...  \n",
       "48  Machine Learning, Data Science, Product Manage...  \n",
       "49  Data Science, Machine Learning, Big Data Analy...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "# Opening target url page on automated chrome browser\n",
    "driver.get('https://www.naukri.com/data-science-recruiters')\n",
    "time.sleep(3)\n",
    "\n",
    "# Creating empty list\n",
    "name=[]\n",
    "desig=[]\n",
    "comp=[]\n",
    "loc=[]\n",
    "\n",
    "# Scrapping details\n",
    "recruiter=[i.text.split('\\n') for i in driver.find_elements(By.XPATH,\"//p[@class='highlightable']\")]\n",
    "for i in recruiter:\n",
    "    try:\n",
    "        name.append(i[0])\n",
    "    except:\n",
    "        name.append('-')\n",
    "    try:\n",
    "        desig.append(i[1])\n",
    "    except:\n",
    "        desig.append('-')\n",
    "    try:\n",
    "        comp.append(i[2])\n",
    "    except:\n",
    "        comp.append('-')\n",
    "    try:\n",
    "        loc.append(i[3])\n",
    "    except:\n",
    "        loc.append('-')\n",
    "skill=[i.text for i in driver.find_elements(By.XPATH,\"//div[@class='hireSec highlightable']\")]    \n",
    "\n",
    "# Saving the lists as dataframe\n",
    "df=pd.DataFrame({'Name':name,'Designation':desig,'Company':comp,'Location':loc,'Skill':skill})\n",
    "print('Data Science recruiters from Naukri')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "06f79efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289e8d40",
   "metadata": {},
   "source": [
    "# Q8 Scrape the details of Highest selling novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e01052a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\")\n",
    "driver.maximize_window()\n",
    "\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c22b36ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Da Vinci Code,The',\n",
       " 'Harry Potter and the Deathly Hallows',\n",
       " \"Harry Potter and the Philosopher's Stone\",\n",
       " 'Harry Potter and the Order of the Phoenix',\n",
       " 'Fifty Shades of Grey',\n",
       " 'Harry Potter and the Goblet of Fire',\n",
       " 'Harry Potter and the Chamber of Secrets',\n",
       " 'Harry Potter and the Prisoner of Azkaban',\n",
       " 'Angels and Demons',\n",
       " \"Harry Potter and the Half-blood Prince:Children's Edition\",\n",
       " 'Fifty Shades Darker',\n",
       " 'Twilight',\n",
       " 'Girl with the Dragon Tattoo,The:Millennium Trilogy',\n",
       " 'Fifty Shades Freed',\n",
       " 'Lost Symbol,The',\n",
       " 'New Moon',\n",
       " 'Deception Point',\n",
       " 'Eclipse',\n",
       " 'Lovely Bones,The',\n",
       " 'Curious Incident of the Dog in the Night-time,The',\n",
       " 'Digital Fortress',\n",
       " 'Short History of Nearly Everything,A',\n",
       " 'Girl Who Played with Fire,The:Millennium Trilogy',\n",
       " 'Breaking Dawn',\n",
       " 'Very Hungry Caterpillar,The:The Very Hungry Caterpillar',\n",
       " 'Gruffalo,The',\n",
       " \"Jamie's 30-Minute Meals\",\n",
       " 'Kite Runner,The',\n",
       " 'One Day',\n",
       " 'Thousand Splendid Suns,A',\n",
       " \"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\",\n",
       " \"Time Traveler's Wife,The\",\n",
       " 'Atonement',\n",
       " \"Bridget Jones's Diary:A Novel\",\n",
       " 'World According to Clarkson,The',\n",
       " \"Captain Corelli's Mandolin\",\n",
       " 'Sound of Laughter,The',\n",
       " 'Life of Pi',\n",
       " 'Billy Connolly',\n",
       " 'Child Called It,A',\n",
       " \"Gruffalo's Child,The\",\n",
       " \"Angela's Ashes:A Memoir of a Childhood\",\n",
       " 'Birdsong',\n",
       " 'Northern Lights:His Dark Materials S.',\n",
       " 'Labyrinth',\n",
       " 'Harry Potter and the Half-blood Prince',\n",
       " 'Help,The',\n",
       " 'Man and Boy',\n",
       " 'Memoirs of a Geisha',\n",
       " \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\",\n",
       " 'Island,The',\n",
       " 'PS, I Love You',\n",
       " 'You are What You Eat:The Plan That Will Change Your Life',\n",
       " 'Shadow of the Wind,The',\n",
       " 'Tales of Beedle the Bard,The',\n",
       " 'Broker,The',\n",
       " \"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\",\n",
       " 'Subtle Knife,The:His Dark Materials S.',\n",
       " 'Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation',\n",
       " \"Delia's How to Cook:(Bk.1)\",\n",
       " 'Chocolat',\n",
       " 'Boy in the Striped Pyjamas,The',\n",
       " \"My Sister's Keeper\",\n",
       " 'Amber Spyglass,The:His Dark Materials S.',\n",
       " 'To Kill a Mockingbird',\n",
       " 'Men are from Mars, Women are from Venus:A Practical Guide for Improvin',\n",
       " 'Dear Fatty',\n",
       " 'Short History of Tractors in Ukrainian,A',\n",
       " 'Hannibal',\n",
       " 'Lord of the Rings,The',\n",
       " 'Stupid White Men:...and Other Sorry Excuses for the State of the Natio',\n",
       " 'Interpretation of Murder,The',\n",
       " 'Sharon Osbourne Extreme:My Autobiography',\n",
       " 'Alchemist,The:A Fable About Following Your Dream',\n",
       " \"At My Mother's Knee ...:and Other Low Joints\",\n",
       " 'Notes from a Small Island',\n",
       " 'Return of the Naked Chef,The',\n",
       " 'Bridget Jones: The Edge of Reason',\n",
       " \"Jamie's Italy\",\n",
       " 'I Can Make You Thin',\n",
       " 'Down Under',\n",
       " 'Summons,The',\n",
       " 'Small Island',\n",
       " 'Nigella Express',\n",
       " 'Brick Lane',\n",
       " \"Memory Keeper's Daughter,The\",\n",
       " 'Room on the Broom',\n",
       " 'About a Boy',\n",
       " 'My Booky Wook',\n",
       " 'God Delusion,The',\n",
       " '\"Beano\" Annual,The',\n",
       " 'White Teeth',\n",
       " 'House at Riverton,The',\n",
       " 'Book Thief,The',\n",
       " 'Nights of Rain and Stars',\n",
       " 'Ghost,The',\n",
       " 'Happy Days with the Naked Chef',\n",
       " 'Hunger Games,The:Hunger Games Trilogy',\n",
       " \"Lost Boy,The:A Foster Child's Search for the Love of a Family\",\n",
       " \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\"]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[]\n",
    "#scraping for name\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[2]\"):\n",
    "    name.append(i.text)\n",
    "\n",
    "name    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a4bf7d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d40e9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Meyer, Stephenie',\n",
       " 'Larsson, Stieg',\n",
       " 'James, E. L.',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Sebold, Alice',\n",
       " 'Haddon, Mark',\n",
       " 'Brown, Dan',\n",
       " 'Bryson, Bill',\n",
       " 'Larsson, Stieg',\n",
       " 'Meyer, Stephenie',\n",
       " 'Carle, Eric',\n",
       " 'Donaldson, Julia',\n",
       " 'Oliver, Jamie',\n",
       " 'Hosseini, Khaled',\n",
       " 'Nicholls, David',\n",
       " 'Hosseini, Khaled',\n",
       " 'Larsson, Stieg',\n",
       " 'Niffenegger, Audrey',\n",
       " 'McEwan, Ian',\n",
       " 'Fielding, Helen',\n",
       " 'Clarkson, Jeremy',\n",
       " 'Bernieres, Louis de',\n",
       " 'Kay, Peter',\n",
       " 'Martel, Yann',\n",
       " 'Stephenson, Pamela',\n",
       " 'Pelzer, Dave',\n",
       " 'Donaldson, Julia',\n",
       " 'McCourt, Frank',\n",
       " 'Faulks, Sebastian',\n",
       " 'Pullman, Philip',\n",
       " 'Mosse, Kate',\n",
       " 'Rowling, J.K.',\n",
       " 'Stockett, Kathryn',\n",
       " 'Parsons, Tony',\n",
       " 'Golden, Arthur',\n",
       " 'McCall Smith, Alexander',\n",
       " 'Hislop, Victoria',\n",
       " 'Ahern, Cecelia',\n",
       " 'McKeith, Gillian',\n",
       " 'Zafon, Carlos Ruiz',\n",
       " 'Rowling, J.K.',\n",
       " 'Grisham, John',\n",
       " 'Atkins, Robert C.',\n",
       " 'Pullman, Philip',\n",
       " 'Truss, Lynne',\n",
       " 'Smith, Delia',\n",
       " 'Harris, Joanne',\n",
       " 'Boyne, John',\n",
       " 'Picoult, Jodi',\n",
       " 'Pullman, Philip',\n",
       " 'Lee, Harper',\n",
       " 'Gray, John',\n",
       " 'French, Dawn',\n",
       " 'Lewycka, Marina',\n",
       " 'Harris, Thomas',\n",
       " 'Tolkien, J. R. R.',\n",
       " 'Moore, Michael',\n",
       " 'Rubenfeld, Jed',\n",
       " 'Osbourne, Sharon',\n",
       " 'Coelho, Paulo',\n",
       " \"O'Grady, Paul\",\n",
       " 'Bryson, Bill',\n",
       " 'Oliver, Jamie',\n",
       " 'Fielding, Helen',\n",
       " 'Oliver, Jamie',\n",
       " 'McKenna, Paul',\n",
       " 'Bryson, Bill',\n",
       " 'Grisham, John',\n",
       " 'Levy, Andrea',\n",
       " 'Lawson, Nigella',\n",
       " 'Ali, Monica',\n",
       " 'Edwards, Kim',\n",
       " 'Donaldson, Julia',\n",
       " 'Hornby, Nick',\n",
       " 'Brand, Russell',\n",
       " 'Dawkins, Richard',\n",
       " '0',\n",
       " 'Smith, Zadie',\n",
       " 'Morton, Kate',\n",
       " 'Zusak, Markus',\n",
       " 'Binchy, Maeve',\n",
       " 'Harris, Robert',\n",
       " 'Oliver, Jamie',\n",
       " 'Collins, Suzanne',\n",
       " 'Pelzer, Dave',\n",
       " 'Oliver, Jamie']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author=[]\n",
    "#scraping for author\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[3]\"):\n",
    "    author.append(i.text)\n",
    "    \n",
    "author "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "18c5c354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "152fecb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5,094,805',\n",
       " '4,475,152',\n",
       " '4,200,654',\n",
       " '4,179,479',\n",
       " '3,758,936',\n",
       " '3,583,215',\n",
       " '3,484,047',\n",
       " '3,377,906',\n",
       " '3,193,946',\n",
       " '2,950,264',\n",
       " '2,479,784',\n",
       " '2,315,405',\n",
       " '2,233,570',\n",
       " '2,193,928',\n",
       " '2,183,031',\n",
       " '2,152,737',\n",
       " '2,062,145',\n",
       " '2,052,876',\n",
       " '2,005,598',\n",
       " '1,979,552',\n",
       " '1,928,900',\n",
       " '1,852,919',\n",
       " '1,814,784',\n",
       " '1,787,118',\n",
       " '1,783,535',\n",
       " '1,781,269',\n",
       " '1,743,266',\n",
       " '1,629,119',\n",
       " '1,616,068',\n",
       " '1,583,992',\n",
       " '1,555,135',\n",
       " '1,546,886',\n",
       " '1,539,428',\n",
       " '1,508,205',\n",
       " '1,489,403',\n",
       " '1,352,318',\n",
       " '1,310,207',\n",
       " '1,310,176',\n",
       " '1,231,957',\n",
       " '1,217,712',\n",
       " '1,208,711',\n",
       " '1,204,058',\n",
       " '1,184,967',\n",
       " '1,181,503',\n",
       " '1,181,093',\n",
       " '1,153,181',\n",
       " '1,132,336',\n",
       " '1,130,802',\n",
       " '1,126,337',\n",
       " '1,115,549',\n",
       " '1,108,328',\n",
       " '1,107,379',\n",
       " '1,104,403',\n",
       " '1,092,349',\n",
       " '1,090,847',\n",
       " '1,087,262',\n",
       " '1,054,196',\n",
       " '1,037,160',\n",
       " '1,023,688',\n",
       " '1,015,956',\n",
       " '1,009,873',\n",
       " '1,004,414',\n",
       " '1,003,780',\n",
       " '1,002,314',\n",
       " '998,213',\n",
       " '992,846',\n",
       " '986,753',\n",
       " '986,115',\n",
       " '970,509',\n",
       " '967,466',\n",
       " '963,353',\n",
       " '962,515',\n",
       " '959,496',\n",
       " '956,114',\n",
       " '945,640',\n",
       " '931,312',\n",
       " '925,425',\n",
       " '924,695',\n",
       " '906,968',\n",
       " '905,086',\n",
       " '890,847',\n",
       " '869,671',\n",
       " '869,659',\n",
       " '862,602',\n",
       " '856,540',\n",
       " '845,858',\n",
       " '842,535',\n",
       " '828,215',\n",
       " '820,563',\n",
       " '816,907',\n",
       " '816,585',\n",
       " '815,586',\n",
       " '814,370',\n",
       " '809,641',\n",
       " '808,900',\n",
       " '807,311',\n",
       " '794,201',\n",
       " '792,187',\n",
       " '791,507',\n",
       " '791,095']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume=[]\n",
    "#scraping for volume\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[4]\"):\n",
    "    volume.append(i.text)\n",
    "\n",
    "volume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "28a4c724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(volume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "51e724f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Transworld',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Transworld',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Quercus',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Pan Macmillan',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Quercus',\n",
       " 'Little, Brown Book',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Bloomsbury',\n",
       " 'Hodder & Stoughton',\n",
       " 'Bloomsbury',\n",
       " 'Quercus',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Canongate',\n",
       " 'HarperCollins',\n",
       " 'Orion',\n",
       " 'Pan Macmillan',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Orion',\n",
       " 'Bloomsbury',\n",
       " 'Penguin',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Headline',\n",
       " 'HarperCollins',\n",
       " 'Penguin',\n",
       " 'Orion',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Profile Books Group',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Random House Childrens Books G',\n",
       " 'Hodder & Stoughton',\n",
       " 'Scholastic Ltd.',\n",
       " 'Random House',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Penguin',\n",
       " 'Random House',\n",
       " 'HarperCollins',\n",
       " 'Penguin',\n",
       " 'Headline',\n",
       " 'Little, Brown Book',\n",
       " 'HarperCollins',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Random House',\n",
       " 'Headline',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Hodder & Stoughton',\n",
       " 'Transworld',\n",
       " 'D.C. Thomson',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Transworld',\n",
       " 'Orion',\n",
       " 'Random House',\n",
       " 'Penguin',\n",
       " 'Scholastic Ltd.',\n",
       " 'Orion',\n",
       " 'Penguin']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publisher=[]\n",
    "#scraping for publisher\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[5]\"):\n",
    "    publisher.append(i.text)\n",
    "\n",
    "    \n",
    "publisher "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c1e69157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(publisher))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f9697d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Romance & Sagas',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Popular Science',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Picture Books',\n",
       " 'Picture Books',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Humour: Collections & General',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Biography: The Arts',\n",
       " 'Autobiography: General',\n",
       " 'Picture Books',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Fitness & Diet',\n",
       " 'General & Literary Fiction',\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Fitness & Diet',\n",
       " 'Young Adult Fiction',\n",
       " 'Usage & Writing Guides',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Popular Culture & Media: General Interest',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'Current Affairs & Issues',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Travel Writing',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'National & Regional Cuisine',\n",
       " 'Fitness & Diet',\n",
       " 'Travel Writing',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Picture Books',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Popular Science',\n",
       " \"Children's Annuals\",\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'Young Adult Fiction',\n",
       " 'Biography: General',\n",
       " 'Food & Drink: General']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre=[]\n",
    "#scraping for genre\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[6]\"):\n",
    "    genre.append(i.text)\n",
    "    \n",
    "genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8c2402fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4afd6fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the Dataframe\n",
    "novels={'Book Name':name,'Author Name':author,'Volumes sold':volume,'Publisher':publisher,'Genre':genre}\n",
    "df=pd.DataFrame(data=novels)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "52a8f873",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7506e92f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

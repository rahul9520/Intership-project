{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "27fd25b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c3e055b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "75125576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first connect to the web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645e3c00",
   "metadata": {},
   "source": [
    "Q1:  Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "\n",
    "1.  First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c4d2a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "37b86128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering designation as required in the question\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d03a70b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering location as required\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "10726e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "912ad815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list to store data the scraped data\n",
    "job_title = []\n",
    "job_location =[]\n",
    "company_name = []\n",
    "experience_required =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "13c068cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst - CRM Platform',\n",
       " 'Data Analyst',\n",
       " 'Senior Data Analyst - Track',\n",
       " 'Contractual Hiring For Top MNC || Business Data Analyst || Bangalore',\n",
       " 'Data Analytics and Interpretation Business Analyst',\n",
       " 'Associate Data Analyst, Connect',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst - 3']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Job title from the given page\n",
    "title_tags= driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d0b998b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Mumbai, Hyderabad/Secunderabad, Pune, Chennai, Ahmedabad',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Job Location from the given page\n",
    "location_tags= driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "02b10274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mobile Premier League',\n",
       " 'Optum',\n",
       " 'Artech infosystem',\n",
       " 'Mobile Premier League',\n",
       " 'G2 Crowd',\n",
       " 'TeamLease',\n",
       " 'Accenture',\n",
       " 'Yara Communications',\n",
       " 'Yara Communications',\n",
       " 'Varite']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Company name from the given page\n",
    "company_tags= driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0305d3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-5 Yrs',\n",
       " '5-10 Yrs',\n",
       " '1-6 Yrs',\n",
       " '2-5 Yrs',\n",
       " '3-8 Yrs',\n",
       " '5-8 Yrs',\n",
       " '6-8 Yrs',\n",
       " '0-2 Yrs',\n",
       " '5-7 Yrs',\n",
       " '3-5 Yrs']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Job Experience from the given page\n",
    "experience_tags= driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)\n",
    "experience_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d2a5b5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3c5cb723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Mobile Premier League</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - CRM Platform</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Mobile Premier League</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst - Track</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>G2 Crowd</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Contractual Hiring For Top MNC || Business Dat...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analytics and Interpretation Business Ana...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Associate Data Analyst, Connect</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Yara Communications</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Yara Communications</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst - 3</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Varite</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                                Senior Data Analyst   \n",
       "1                                Senior Data Analyst   \n",
       "2                        Data Analyst - CRM Platform   \n",
       "3                                       Data Analyst   \n",
       "4                        Senior Data Analyst - Track   \n",
       "5  Contractual Hiring For Top MNC || Business Dat...   \n",
       "6  Data Analytics and Interpretation Business Ana...   \n",
       "7                    Associate Data Analyst, Connect   \n",
       "8                                Senior Data Analyst   \n",
       "9                                   Data Analyst - 3   \n",
       "\n",
       "                                        Job_location           Company_name  \\\n",
       "0                                Bangalore/Bengaluru  Mobile Premier League   \n",
       "1                                Bangalore/Bengaluru                  Optum   \n",
       "2  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...      Artech infosystem   \n",
       "3                                Bangalore/Bengaluru  Mobile Premier League   \n",
       "4                                Bangalore/Bengaluru               G2 Crowd   \n",
       "5                                Bangalore/Bengaluru              TeamLease   \n",
       "6                                Bangalore/Bengaluru              Accenture   \n",
       "7                                Bangalore/Bengaluru    Yara Communications   \n",
       "8                                Bangalore/Bengaluru    Yara Communications   \n",
       "9                                Bangalore/Bengaluru                 Varite   \n",
       "\n",
       "  Exp_required  \n",
       "0      3-5 Yrs  \n",
       "1     5-10 Yrs  \n",
       "2      1-6 Yrs  \n",
       "3      2-5 Yrs  \n",
       "4      3-8 Yrs  \n",
       "5      5-8 Yrs  \n",
       "6      6-8 Yrs  \n",
       "7      0-2 Yrs  \n",
       "8      5-7 Yrs  \n",
       "9      3-5 Yrs  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the dataframe from above data\n",
    "df = pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Exp_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68e7822",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0e588b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "96f39125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering \"Data Scientist\" in skills/designations/companies\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fd076a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering location as Bangalore\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fae8e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[6]\")\n",
    "search.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b21ddde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list to store data the scraped data\n",
    "job_title = []\n",
    "job_location =[]\n",
    "company_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d2d74828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Analystics & Modeling Specialist',\n",
       " 'Analystics & Modeling Specialist',\n",
       " 'Job Opportunity on Data Science_ Python with Techmahindra',\n",
       " 'Assistant Manager - Data Science',\n",
       " 'Hiring For DATA Scientist @ NTT DATA Business Solution India',\n",
       " 'Data Scientist/AIML Engineer',\n",
       " 'ACN - Applied Intelligence - Data & Insights - CPG - 09',\n",
       " 'Data Scientist',\n",
       " 'ACN - Applied Intelligence - C4DI - Sustainability - 09',\n",
       " 'Hiring Data Science Intern - DataTrained Education']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Job title from the given page\n",
    "title_tags= driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:9]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "993781d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru, Kolkata, Mumbai, Hyderabad/Secunderabad, Pune, Chennai, delhi ncr',\n",
       " 'Bangalore/Bengaluru, Kolkata, Hyderabad/Secunderabad, Pune, Chennai, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru, Mumbai, Pune',\n",
       " 'Bangalore/Bengaluru, Noida, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru, Mumbai, Hyderabad/Secunderabad',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Noida, Kolkata, Hyderabad/Secunderabad, Pune, Ahmedabad, Chennai, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru, Mumbai']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Job Location from the given page\n",
    "location_tags= driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bf04e1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accenture',\n",
       " 'Tech Mahindra',\n",
       " 'CitiusTech',\n",
       " 'NTT DATA Business Solutions Private Limited',\n",
       " 'upGrad',\n",
       " 'Accenture',\n",
       " 'IBM',\n",
       " 'Accenture',\n",
       " 'DataTrained',\n",
       " 'Fractal Analytics']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Company name from the given page\n",
    "company_tags= driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ca9907fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "992464f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Job Opportunity on Data Science_ Python with T...</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>upGrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist/AIML Engineer</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACN - Applied Intelligence - Data &amp; Insights -...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACN - Applied Intelligence - C4DI - Sustainabi...</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Kolkata, Hyderabad...</td>\n",
       "      <td>DataTrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring Data Science Intern - DataTrained Educa...</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                   Analystics & Modeling Specialist   \n",
       "1                   Analystics & Modeling Specialist   \n",
       "2  Job Opportunity on Data Science_ Python with T...   \n",
       "3                   Assistant Manager - Data Science   \n",
       "4  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "5                       Data Scientist/AIML Engineer   \n",
       "6  ACN - Applied Intelligence - Data & Insights -...   \n",
       "7                                     Data Scientist   \n",
       "8  ACN - Applied Intelligence - C4DI - Sustainabi...   \n",
       "9  Hiring Data Science Intern - DataTrained Educa...   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "1  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "2                  Bangalore/Bengaluru, Mumbai, Pune   \n",
       "3  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "4  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8  Bangalore/Bengaluru, Noida, Kolkata, Hyderabad...   \n",
       "9                        Bangalore/Bengaluru, Mumbai   \n",
       "\n",
       "                                  Company_name  \n",
       "0                                    Accenture  \n",
       "1                                Tech Mahindra  \n",
       "2                                   CitiusTech  \n",
       "3  NTT DATA Business Solutions Private Limited  \n",
       "4                                       upGrad  \n",
       "5                                    Accenture  \n",
       "6                                          IBM  \n",
       "7                                    Accenture  \n",
       "8                                  DataTrained  \n",
       "9                            Fractal Analytics  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the dataframe from above data\n",
    "df = pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aecc40",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below: You have to use the location and salary filter. You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company name, experience required. The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "\n",
    "The task will be done as shown in the below steps:\n",
    "\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data. Note: All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a45637d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "696ad943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering \"Data Scientist\" in skills/designations/companies\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "68c3c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering location as Bangalore\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Delhi/NCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6a184177",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[6]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1576aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "# Since job_location is Delhi/NCR a single element applied absolute XPATH\n",
    "job_location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[13]/div[2]/div[2]/label/p/span[1]\")\n",
    "job_location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9b8fc82a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementNotInteractableException",
     "evalue": "Message: element not interactable\n  (Session info: chrome=105.0.5195.102)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x0107DF13+2219795]\n\tOrdinal0 [0x01012841+1779777]\n\tOrdinal0 [0x00F24100+803072]\n\tOrdinal0 [0x00F53FB6+999350]\n\tOrdinal0 [0x00F49B76+957302]\n\tOrdinal0 [0x00F6E7FC+1107964]\n\tOrdinal0 [0x00F494B4+955572]\n\tOrdinal0 [0x00F6EA14+1108500]\n\tOrdinal0 [0x00F7F192+1175954]\n\tOrdinal0 [0x00F6E616+1107478]\n\tOrdinal0 [0x00F47F89+950153]\n\tOrdinal0 [0x00F48F56+954198]\n\tGetHandleVerifier [0x01372CB2+3040210]\n\tGetHandleVerifier [0x01362BB4+2974420]\n\tGetHandleVerifier [0x01116A0A+565546]\n\tGetHandleVerifier [0x01115680+560544]\n\tOrdinal0 [0x01019A5C+1808988]\n\tOrdinal0 [0x0101E3A8+1827752]\n\tOrdinal0 [0x0101E495+1827989]\n\tOrdinal0 [0x010280A4+1867940]\n\tBaseThreadInitThunk [0x766BFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77DA7A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77DA7A6E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [93]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Since salary is 3-6 Lakhs a single element applied absolute XPATH\u001b[39;00m\n\u001b[0;32m      2\u001b[0m salary \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/html/body/div[1]/div[4]/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/p/span[1]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43msalary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:88\u001b[0m, in \u001b[0;36mWebElement.click\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclick\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;124;03m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLICK_ELEMENT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:396\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    394\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    395\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:428\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    426\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 428\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[0;32m    430\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:243\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mElementNotInteractableException\u001b[0m: Message: element not interactable\n  (Session info: chrome=105.0.5195.102)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x0107DF13+2219795]\n\tOrdinal0 [0x01012841+1779777]\n\tOrdinal0 [0x00F24100+803072]\n\tOrdinal0 [0x00F53FB6+999350]\n\tOrdinal0 [0x00F49B76+957302]\n\tOrdinal0 [0x00F6E7FC+1107964]\n\tOrdinal0 [0x00F494B4+955572]\n\tOrdinal0 [0x00F6EA14+1108500]\n\tOrdinal0 [0x00F7F192+1175954]\n\tOrdinal0 [0x00F6E616+1107478]\n\tOrdinal0 [0x00F47F89+950153]\n\tOrdinal0 [0x00F48F56+954198]\n\tGetHandleVerifier [0x01372CB2+3040210]\n\tGetHandleVerifier [0x01362BB4+2974420]\n\tGetHandleVerifier [0x01116A0A+565546]\n\tGetHandleVerifier [0x01115680+560544]\n\tOrdinal0 [0x01019A5C+1808988]\n\tOrdinal0 [0x0101E3A8+1827752]\n\tOrdinal0 [0x0101E495+1827989]\n\tOrdinal0 [0x010280A4+1867940]\n\tBaseThreadInitThunk [0x766BFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77DA7A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77DA7A6E+238]\n"
     ]
    }
   ],
   "source": [
    "# Since salary is 3-6 Lakhs a single element applied absolute XPATH\n",
    "salary = driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/p/span[1]\")\n",
    "salary.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f093bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating empty list to store data the scraped data\n",
    "job_title = []\n",
    "job_location =[]\n",
    "company_name = []\n",
    "experience_required =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0c7e817f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hiring For DATA Scientist @ NTT DATA Business Solution India',\n",
       " 'Data Scientist',\n",
       " 'Forecasting Analyst/ Data Scientist (US Client)',\n",
       " 'Data Scientist',\n",
       " 'ACN - Applied Intelligence - C4DI - Sustainability - 07',\n",
       " 'ACN - Applied Intelligence - C4DI - Insight Delivery - 09',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Senior Analyst-Data Science',\n",
       " 'Senior Analyst-Data Science']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Job title from the given page\n",
    "title_tags= driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "062a7250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gurgaon/Gurugram, Noida, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Gurgaon/Gurugram, New Delhi, Pune, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru\\n(WFH during Covid)',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Gurgaon/Gurugram, Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram, Kolkata, Hyderabad/Secunderabad, Pune, Ahmedabad, Bangalore/Bengaluru, Delhi / NCR\\n(WFH during Covid)',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Gurgaon/Gurugram']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Job Location from the given page\n",
    "location_tags= driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2b3fb4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NTT DATA Business Solutions Private Limited',\n",
       " 'ZS Associates',\n",
       " 'Concentrix',\n",
       " 'Optum',\n",
       " 'Accenture',\n",
       " 'Accenture',\n",
       " 'OakNorth',\n",
       " 'Absolutdata',\n",
       " 'Accenture',\n",
       " 'Accenture']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Company name from the given page\n",
    "company_tags= driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "edfd5b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4-9 Yrs',\n",
       " '5-8 Yrs',\n",
       " '3-8 Yrs',\n",
       " '3-8 Yrs',\n",
       " '6-10 Yrs',\n",
       " '4-6 Yrs',\n",
       " '3-7 Yrs',\n",
       " '5-10 Yrs',\n",
       " '5-8 Yrs',\n",
       " '5-8 Yrs']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(3)\n",
    "# Scraping Job Experience from the given page\n",
    "experience_tags= driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)\n",
    "experience_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5dd4b6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "124944cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Gurgaon/Gurugram, Noida, Hyderabad/Secunderaba...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, New Delhi, Pune, Bangalore/B...</td>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forecasting Analyst/ Data Scientist (US Client)</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru\\n(WFH du...</td>\n",
       "      <td>Concentrix</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN - Applied Intelligence - C4DI - Sustainabi...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACN - Applied Intelligence - C4DI - Insight De...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Hyderabad/Secunderabad, Bang...</td>\n",
       "      <td>OakNorth</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Kolkata, Hyderabad/Secundera...</td>\n",
       "      <td>Absolutdata</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "1                                     Data Scientist   \n",
       "2    Forecasting Analyst/ Data Scientist (US Client)   \n",
       "3                                     Data Scientist   \n",
       "4  ACN - Applied Intelligence - C4DI - Sustainabi...   \n",
       "5  ACN - Applied Intelligence - C4DI - Insight De...   \n",
       "6                                     Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8                        Senior Analyst-Data Science   \n",
       "9                        Senior Analyst-Data Science   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0  Gurgaon/Gurugram, Noida, Hyderabad/Secunderaba...   \n",
       "1  Gurgaon/Gurugram, New Delhi, Pune, Bangalore/B...   \n",
       "2  Gurgaon/Gurugram, Bangalore/Bengaluru\\n(WFH du...   \n",
       "3                                   Gurgaon/Gurugram   \n",
       "4                                   Gurgaon/Gurugram   \n",
       "5                                   Gurgaon/Gurugram   \n",
       "6  Gurgaon/Gurugram, Hyderabad/Secunderabad, Bang...   \n",
       "7  Gurgaon/Gurugram, Kolkata, Hyderabad/Secundera...   \n",
       "8                                   Gurgaon/Gurugram   \n",
       "9                                   Gurgaon/Gurugram   \n",
       "\n",
       "                                  Company_name Exp_required  \n",
       "0  NTT DATA Business Solutions Private Limited      4-9 Yrs  \n",
       "1                                ZS Associates      5-8 Yrs  \n",
       "2                                   Concentrix      3-8 Yrs  \n",
       "3                                        Optum      3-8 Yrs  \n",
       "4                                    Accenture     6-10 Yrs  \n",
       "5                                    Accenture      4-6 Yrs  \n",
       "6                                     OakNorth      3-7 Yrs  \n",
       "7                                  Absolutdata     5-10 Yrs  \n",
       "8                                    Accenture      5-8 Yrs  \n",
       "9                                    Accenture      5-8 Yrs  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the dataframe from above data\n",
    "df = pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Exp_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5944b5e2",
   "metadata": {},
   "source": [
    "Q4 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "\n",
    "Brand Product Description Price To scrape the data you have to go through following steps: Go to flipkart webpage by url https://www.flipkart.com/ Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon after that you will reach to a webpage having a lot of sunglasses. From this page you can scrap the required data as usual. after scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "87646703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the flipkart on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "605be6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering product in search bar as required\n",
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('Sunglasses')\n",
    "\n",
    "time.sleep(3)\n",
    "# Serching Item\n",
    "search = driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ce95bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the empty list\n",
    "Brand = []\n",
    "Product_Description = []\n",
    "Price = []\n",
    "Discount = []\n",
    " \n",
    "time.sleep(3)\n",
    "\n",
    "#Scrapping the required details\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')      \n",
    "    for i in brand_tags:\n",
    "        Brand.append(i.text)     \n",
    "        \n",
    "    Product_Desc_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')     \n",
    "    for i in Product_Desc_tags:\n",
    "        Product_Description.append(i.text)    \n",
    "        \n",
    "    Price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]') \n",
    "    for i in Price_tags:\n",
    "        Price.append(i.text)\n",
    "        \n",
    "    Discount_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in Discount_tags:\n",
    "        Discount.append(i.text)\n",
    "        \n",
    "    nxt_button=driver.find_elements(By.XPATH,\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href')) \n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9c64ce8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Description),len(Price),len(Discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "52326d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Desc</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹319</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹449</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (50)</td>\n",
       "      <td>₹1,049</td>\n",
       "      <td>47% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹359</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Round Sun...</td>\n",
       "      <td>₹999</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wrap-around Sunglasses (63)</td>\n",
       "      <td>₹710</td>\n",
       "      <td>21% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹449</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (55)</td>\n",
       "      <td>₹189</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (50)</td>\n",
       "      <td>₹699</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                       Product_Desc   Price  \\\n",
       "0         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹799   \n",
       "1   ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...    ₹319   \n",
       "2   ROZZETTA CRAFT  UV Protection Retro Square Sunglasses (Free Size)    ₹449   \n",
       "3    VINCENT CHASE     Polarized, UV Protection Round Sunglasses (50)  ₹1,049   \n",
       "4   ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...    ₹359   \n",
       "..             ...                                                ...     ...   \n",
       "95   VINCENT CHASE  by Lenskart Polarized, UV Protection Round Sun...    ₹999   \n",
       "96        Fastrack          UV Protection Wrap-around Sunglasses (63)    ₹710   \n",
       "97  ROZZETTA CRAFT  UV Protection Retro Square Sunglasses (Free Size)    ₹449   \n",
       "98  kingsunglasses          UV Protection Rectangular Sunglasses (55)    ₹189   \n",
       "99   VINCENT CHASE          UV Protection Rectangular Sunglasses (50)    ₹699   \n",
       "\n",
       "   Discount  \n",
       "0   20% off  \n",
       "1   84% off  \n",
       "2   79% off  \n",
       "3   47% off  \n",
       "4   82% off  \n",
       "..      ...  \n",
       "95  50% off  \n",
       "96  21% off  \n",
       "97  80% off  \n",
       "98  85% off  \n",
       "99  65% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe from the above data\n",
    "df = pd.DataFrame({'Brand':Brand[:100],'Product_Desc':Product_Description[:100],'Price':Price[:100],'Discount':Discount[:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72dcf99",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field. You have to scrape 4 attributes of each sneaker:\n",
    "\n",
    "Brand Product Description Price Discount As shown in the below image, you have to scrape the tick marked attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "73215b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the flipkart on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0f5d8f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering product in search bar as required\n",
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('Sneakers')\n",
    "\n",
    "time.sleep(3)\n",
    "# Serching Item\n",
    "search = driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "914c9482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the empty list\n",
    "Brand = []\n",
    "Product_Description = []\n",
    "Price = []\n",
    "Discount = []\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "eb0ef9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "\n",
    "#Scrapping the required details\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')      \n",
    "    for i in brand_tags:\n",
    "        Brand.append(i.text)     \n",
    "        \n",
    "    Product_Desc_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')     \n",
    "    for i in Product_Desc_tags:\n",
    "        Product_Description.append(i.text)    \n",
    "        \n",
    "    Price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]') \n",
    "    for i in Price_tags:\n",
    "        Price.append(i.text)\n",
    "        \n",
    "    Discount_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in Discount_tags:\n",
    "        Discount.append(i.text)\n",
    "        \n",
    "    nxt_button=driver.find_elements(By.XPATH,\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href')) \n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "464845db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 114 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Description),len(Price),len(Discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "91957ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Desc</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAMPUS</td>\n",
       "      <td>CAMP DENVER Sneakers For Men</td>\n",
       "      <td>₹1,849</td>\n",
       "      <td>7% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Latest Design Trendy and Comfortable Sports Sh...</td>\n",
       "      <td>₹199</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TR</td>\n",
       "      <td>Casual White Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>CAMPUS</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,849</td>\n",
       "      <td>7% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>KWIK FIT</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Skypy-31 Walking Shoes,Training Shoes,Sneakers...</td>\n",
       "      <td>₹450</td>\n",
       "      <td>69% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROCKFIELD</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹333</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand                                       Product_Desc   Price  \\\n",
       "0      CAMPUS                       CAMP DENVER Sneakers For Men  ₹1,849   \n",
       "1      BRUTON  Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...    ₹499   \n",
       "2       BIRDE  Latest Design Trendy and Comfortable Sports Sh...    ₹199   \n",
       "3          TR                      Casual White Sneakers For Men    ₹299   \n",
       "4      BRUTON  Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...    ₹499   \n",
       "..        ...                                                ...     ...   \n",
       "95     CAMPUS                                   Sneakers For Men  ₹1,849   \n",
       "96   KWIK FIT                                   Sneakers For Men    ₹399   \n",
       "97      BIRDE  Skypy-31 Walking Shoes,Training Shoes,Sneakers...    ₹450   \n",
       "98  ROCKFIELD                                   Sneakers For Men    ₹333   \n",
       "99      BIRDE                                   Sneakers For Men    ₹449   \n",
       "\n",
       "   Discount  \n",
       "0    7% off  \n",
       "1   85% off  \n",
       "2   80% off  \n",
       "3   80% off  \n",
       "4   85% off  \n",
       "..      ...  \n",
       "95   7% off  \n",
       "96  80% off  \n",
       "97  69% off  \n",
       "98  66% off  \n",
       "99  55% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe from the above data\n",
    "df = pd.DataFrame({'Brand':Brand[:100],'Product_Desc':Product_Description[:100],'Price':Price[:100],'Discount':Discount[:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eb3d94",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes Set second Price filter and Color filter to “Black”, as shown in the below image.\n",
    "\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fc056797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the Myntra website on automated chrome browser\n",
    "driver.get(\"https://www.myntra.com/shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "52ec47a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(4)\n",
    "\n",
    "#clicking on price filter\n",
    "pricebutton = driver.find_element(By.XPATH,\"//ul[@class='price-list']/li[2]/label/div\")\n",
    "pricebutton.click()\n",
    "\n",
    "#clicking on black colour \n",
    "blackbutton = driver.find_element(By.XPATH,'//li[@class=\"colour-listItem\"]/label/div')\n",
    "blackbutton.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "28a7de20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the empty list\n",
    "Brand = []\n",
    "Product_Description = []\n",
    "Price = []\n",
    "\n",
    "#Scrapping the required details\n",
    "start=0\n",
    "end=2\n",
    "for page in range(start,end):\n",
    "    brand_tags=driver.find_elements(By.XPATH,\"//div[@class='product-productMetaInfo']\")      \n",
    "    for i in brand_tags:\n",
    "        Brand.append(i.text)     \n",
    "        \n",
    "    Product_Desc_tags=driver.find_elements(By.XPATH,\"//div[@class='product-productMetaInfo']/h4[1]\")     \n",
    "    for i in Product_Desc_tags:\n",
    "        Product_Description.append(i.text)    \n",
    "        \n",
    "    Price_tags=driver.find_elements(By.XPATH,'//div[@class=\"product-price\"]') \n",
    "    for i in Price_tags:\n",
    "        Price.append(i.text) \n",
    "        \n",
    "        nxt_button=driver.find_elements(By.XPATH,'//a[@rel=\"next\"]')\n",
    "\n",
    "try:\n",
    "    driver.get(nxt_button[1].get_attribute('href')) \n",
    "except:\n",
    "    driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f87ef901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Description),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "22227313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Desc</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red Tape\\nMen Walking Shoes\\nRs. 1619Rs. 5399(...</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 1619Rs. 5399(70% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike\\nMen ZOOM WINFLO8 Running Shoes\\nRs. 7880...</td>\n",
       "      <td>Men ZOOM WINFLO8 Running Shoes</td>\n",
       "      <td>Rs. 7880Rs. 8295(5% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Roadster\\nMen Sneakers\\nRs. 872Rs. 3795(77% OFF)</td>\n",
       "      <td>Men Sneakers</td>\n",
       "      <td>Rs. 872Rs. 3795(77% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Red Tape\\nMen Walking Shoes\\nRs. 1589Rs. 5299(...</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 1589Rs. 5299(70% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma\\nMen Enzo Running Shoes\\nRs. 3024Rs. 5499...</td>\n",
       "      <td>Men Enzo Running Shoes</td>\n",
       "      <td>Rs. 3024Rs. 5499(45% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>U.S. Polo Assn.\\nMen Solid Horsebit Loafers\\nR...</td>\n",
       "      <td>Men Solid Horsebit Loafers</td>\n",
       "      <td>Rs. 2089Rs. 3799(45% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>AfroJack\\nMen Colourblocked Sneakers\\nRs. 749R...</td>\n",
       "      <td>Men Colourblocked Sneakers</td>\n",
       "      <td>Rs. 749Rs. 3745(80% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Nike\\nKids Revolution 4 Running\\nRs. 1118Rs. 3...</td>\n",
       "      <td>Kids Revolution 4 Running</td>\n",
       "      <td>Rs. 1118Rs. 3495(68% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Puma\\nUnisex Turino FSL Trainers\\nRs. 3119Rs. ...</td>\n",
       "      <td>Unisex Turino FSL Trainers</td>\n",
       "      <td>Rs. 3119Rs. 4799(35% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bond Street By Red Tape\\nMen Walking Shoes\\nRs...</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 979Rs. 4899(80% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Brand  \\\n",
       "0   Red Tape\\nMen Walking Shoes\\nRs. 1619Rs. 5399(...   \n",
       "1   Nike\\nMen ZOOM WINFLO8 Running Shoes\\nRs. 7880...   \n",
       "2    Roadster\\nMen Sneakers\\nRs. 872Rs. 3795(77% OFF)   \n",
       "3   Red Tape\\nMen Walking Shoes\\nRs. 1589Rs. 5299(...   \n",
       "4   Puma\\nMen Enzo Running Shoes\\nRs. 3024Rs. 5499...   \n",
       "..                                                ...   \n",
       "95  U.S. Polo Assn.\\nMen Solid Horsebit Loafers\\nR...   \n",
       "96  AfroJack\\nMen Colourblocked Sneakers\\nRs. 749R...   \n",
       "97  Nike\\nKids Revolution 4 Running\\nRs. 1118Rs. 3...   \n",
       "98  Puma\\nUnisex Turino FSL Trainers\\nRs. 3119Rs. ...   \n",
       "99  Bond Street By Red Tape\\nMen Walking Shoes\\nRs...   \n",
       "\n",
       "                      Product_Desc                      Price  \n",
       "0                Men Walking Shoes  Rs. 1619Rs. 5399(70% OFF)  \n",
       "1   Men ZOOM WINFLO8 Running Shoes   Rs. 7880Rs. 8295(5% OFF)  \n",
       "2                     Men Sneakers   Rs. 872Rs. 3795(77% OFF)  \n",
       "3                Men Walking Shoes  Rs. 1589Rs. 5299(70% OFF)  \n",
       "4           Men Enzo Running Shoes  Rs. 3024Rs. 5499(45% OFF)  \n",
       "..                             ...                        ...  \n",
       "95      Men Solid Horsebit Loafers  Rs. 2089Rs. 3799(45% OFF)  \n",
       "96      Men Colourblocked Sneakers   Rs. 749Rs. 3745(80% OFF)  \n",
       "97       Kids Revolution 4 Running  Rs. 1118Rs. 3495(68% OFF)  \n",
       "98      Unisex Turino FSL Trainers  Rs. 3119Rs. 4799(35% OFF)  \n",
       "99               Men Walking Shoes   Rs. 979Rs. 4899(80% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe from the above data\n",
    "df = pd.DataFrame({'Brand':Brand[:100],'Product_Desc':Product_Description[:100],'Price':Price[:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ab20df",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. This task will be done in following steps:\n",
    "\n",
    "First get the webpage https://www.flipkart.com/\n",
    "Enter “iphone 11” in “Search” field .\n",
    "Then click the search button\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "\n",
    "Rating\n",
    "Review summary\n",
    "Full review\n",
    "You have to scrape this data for first 100 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5743b843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the flipkart on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e352d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering product in search bar as required\n",
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('iphone 11')\n",
    "\n",
    "time.sleep(3)\n",
    "# Serching Item\n",
    "search = driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "051f99ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,'//div[@class=\"_4rR01T\"]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "01f005c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list\n",
    "Rating = []\n",
    "Review_summary = []\n",
    "Full_review = []\n",
    "\n",
    "start=0\n",
    "end=10\n",
    "\n",
    "# Scraping rating from given page\n",
    "for page in range(start,end):\n",
    "    rate = driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rate:\n",
    "        Rating.append(i.text)\n",
    "        \n",
    "# Scraping review summary from given page\n",
    "    review = driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review:\n",
    "        Review_summary.append(i.text)\n",
    "\n",
    "# Scraping full review from given page\n",
    "    fullreview = driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in fullreview:\n",
    "        Full_review.append(i.text)  \n",
    "        \n",
    "    nxt_button=driver.find_elements(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "time.sleep(11)\n",
    "try:\n",
    "    driver.get(nxt_button[1].get_attribute('href')) \n",
    "except:\n",
    "    driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "03e20194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(Rating),len(Review_summary),len(Full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efccee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
